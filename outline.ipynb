{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Stock Forecaster  \n",
    "**(FMP + Kronos + FinText-TSFM | Signal-Only, Point-in-Time Safe)**\n",
    "\n",
    "---\n",
    "\n",
    "## 0) Project Explanation & Philosophy\n",
    "\n",
    "### What this project is\n",
    "\n",
    "This project builds a **decision-support forecasting model** that answers one core question:\n",
    "\n",
    "> **Which AI stocks are most attractive to buy today, on a risk-adjusted basis, over the next 20 / 60 / 90 trading days?**\n",
    "\n",
    "The system outputs **ranked stock recommendations and return distributions**, not trades.  \n",
    "Its purpose is to generate **credible alpha signals** that survive realistic financial constraints.\n",
    "\n",
    "The design explicitly accounts for:\n",
    "- non-stationary market behavior,\n",
    "- weak and noisy financial signals,\n",
    "- transaction costs and liquidity effects,\n",
    "- and strict point-in-time (PIT) correctness.\n",
    "\n",
    "---\n",
    "\n",
    "### What this project is NOT\n",
    "\n",
    "This project does **not**:\n",
    "- place trades,\n",
    "- connect to brokers,\n",
    "- optimize execution,\n",
    "- or manage live capital.\n",
    "\n",
    "Any portfolio-related logic exists **only to validate signal realism**, not to implement trading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core modeling philosophy\n",
    "\n",
    "1. **Ranking beats regression**  \n",
    "   Relative ordering of stocks is more stable and economically useful than exact price prediction.\n",
    "\n",
    "2. **Point-in-time correctness is non-negotiable**  \n",
    "   Any signal unavailable at time *T* must not influence predictions at time *T*.\n",
    "\n",
    "3. **Economic validity > statistical fit**  \n",
    "   Signals must survive transaction costs, turnover, and regime shifts.\n",
    "\n",
    "4. **Multiple weak signals > single strong model**  \n",
    "   Combine complementary views:\n",
    "   - price dynamics (Kronos),\n",
    "   - return structure (FinText-TSFM),\n",
    "   - fundamentals and context (tabular models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) System Outputs (Signal-Only)\n",
    "\n",
    "At each rebalance date **T**, for each stock and horizon (20 / 60 / 90 trading days):\n",
    "\n",
    "### Per-stock outputs\n",
    "- **Expected excess return** vs benchmark (QQQ default; XLK/SMH optional)\n",
    "- **Return distribution** (5th / 50th / 95th percentiles)\n",
    "- **Alpha ranking score** (cross-sectional)\n",
    "- **Confidence score** (calibrated uncertainty)\n",
    "- **Key drivers** (feature blocks influencing the rank)\n",
    "\n",
    "### Cross-sectional outputs\n",
    "- Ranked list: **Top buys / neutral / avoid**\n",
    "- Optional confidence buckets (high vs low confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Scope & Validation Philosophy (Signal-Only)\n",
    "\n",
    "### Scope\n",
    "- The system produces **signals**, not trades.\n",
    "- No execution or order placement logic is implemented.\n",
    "\n",
    "### Why portfolio concepts still appear\n",
    "Portfolio concepts (turnover, costs, constraints) are used **only for evaluation realism**, to answer:\n",
    "> *Would these signals remain economically meaningful if followed by an investor?*\n",
    "\n",
    "### Optional realism check\n",
    "- Paper trading (e.g., Alpaca paper) may be used **post-hoc** to validate:\n",
    "  - timestamp integrity,\n",
    "  - universe construction,\n",
    "  - signal stability.\n",
    "- Paper trading results are **never** used for training or model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Data & Point-in-Time Infrastructure (FMP-First)\n",
    "\n",
    "### 3.1 Data sources\n",
    "- **Market**: Daily OHLCV, splits, dividends\n",
    "- **Fundamentals**: Income, balance sheet, cash flow (quarterly)\n",
    "- **Metadata**: Sector, industry, shares outstanding, market cap\n",
    "- **Events**: Earnings dates with announcement time\n",
    "- **Benchmarks**: QQQ (default), optional XLK / SMH\n",
    "- **Regime proxies**: VIX, market breadth, rate proxies\n",
    "\n",
    "---\n",
    "\n",
    "### 3.2 Point-in-time (PIT) rules\n",
    "\n",
    "Each datapoint stores:\n",
    "- `value`\n",
    "- `observed_at` (first public release timestamp)\n",
    "- `effective_from`\n",
    "- `source`\n",
    "\n",
    "Rules:\n",
    "- Fundamentals are **as-reported**, never restated historically\n",
    "- Forward-fill allowed **only after** `observed_at`\n",
    "- No feature may use information released after the cutoff time\n",
    "\n",
    "---\n",
    "\n",
    "### 3.3 Daily cutoff policy (anti-lookahead)\n",
    "\n",
    "- Fixed cutoff time (e.g., 4:00pm ET)\n",
    "- Features for date *T* may only use data with timestamps â‰¤ cutoff(T)\n",
    "- Earnings handling distinguishes pre-market vs after-close announcements\n",
    "\n",
    "---\n",
    "\n",
    "### 3.4 Data audits & bias detection\n",
    "\n",
    "Automated checks:\n",
    "- PIT violation scanner\n",
    "- Survivorship reconstruction audit\n",
    "- Corporate action sanity checks\n",
    "- Missingness and outlier detection\n",
    "\n",
    "**Success criteria**\n",
    "- < 0.1% PIT violations\n",
    "- Universe reproducible for any historical date\n",
    "- All datasets auditable and replayable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Survivorship-Safe Dynamic Universe\n",
    "\n",
    "### 4.1 Universe construction (critical)\n",
    "\n",
    "At each rebalance date **T**:\n",
    "- Start with all U.S. equities meeting liquidity and price thresholds\n",
    "- Filter by AI-relevant sector / industry tags\n",
    "- Select **Top N by market cap as-of T**\n",
    "- Persist constituents with timestamp\n",
    "\n",
    "Hardcoded \"today's winners\" are explicitly disallowed.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.2 Delistings & mergers\n",
    "- Delisted stocks remain in historical universes where data exists\n",
    "- Missing data is explicitly modeled rather than silently dropped\n",
    "\n",
    "**Success criteria**\n",
    "- Constituents vary meaningfully through time\n",
    "- Backtests include both winners and failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Feature Engineering (Bias-Safe)\n",
    "\n",
    "### 5.0 Readiness Checklist & Implementation Plan\n",
    "\n",
    "#### Infrastructure Available (from Chapters 3-4) âœ…\n",
    "| Component | Module | What It Provides |\n",
    "|-----------|--------|------------------|\n",
    "| Prices | `FMPClient.get_historical_prices()` | Split-adjusted OHLCV with `observed_at` |\n",
    "| Fundamentals | `FMPClient.get_income_statement()` etc. | With `fillingDate` for PIT |\n",
    "| Volume/ADV | `DuckDBPITStore.get_avg_volume()` | Computed from OHLCV |\n",
    "| Events | `EventStore` | EARNINGS, FILING, SENTIMENT with PIT |\n",
    "| Earnings | `AlphaVantageClient` + `ExpectationsClient` | BMO/AMC timing, surprises |\n",
    "| Regime/VIX | `FMPClient.get_index_historical()` | SPY, VIX for regime detection |\n",
    "| Universe | `UniverseBuilder` | FULL survivorship via Polygon |\n",
    "| ID Mapping | `SecurityMaster` | Stable IDs, ticker changes |\n",
    "| Calendar | `TradingCalendarImpl` | NYSE holidays, cutoffs |\n",
    "| Caching | All clients | `data/cache/*` directories |\n",
    "\n",
    "#### API Keys Available âœ…\n",
    "- `FMP_KEYS` - Prices, fundamentals, profiles (free tier: 250/day)\n",
    "- `POLYGON_KEYS` - Symbol master, universe (free tier: 5/min)\n",
    "- `ALPHAVANTAGE_KEYS` - Earnings calendar (free tier: 25/day)\n",
    "\n",
    "---\n",
    "\n",
    "#### Chapter 5 TODO List âœ… COMPLETE\n",
    "\n",
    "**5.1 Targets (Labels)** âœ…\n",
    "- [x] Implement forward excess return calculation vs QQQ benchmark\n",
    "- [x] Create label generator for 20/60/90 trading day horizons\n",
    "- [x] Ensure labels are strictly PIT-safe (no future leakage)\n",
    "- [x] **v2: Total return labels (dividends included) - DEFAULT**\n",
    "\n",
    "**5.2 Price & Volume Features** âœ…\n",
    "- [x] Momentum features (1m, 3m, 6m, 12m returns)\n",
    "- [x] Volatility (realized vol, vol-of-vol)\n",
    "- [x] Drawdown (max drawdown, current vs high)\n",
    "- [x] Relative strength vs universe median\n",
    "- [x] Beta vs benchmark (rolling window)\n",
    "- [x] ADV and volatility-adjusted ADV\n",
    "\n",
    "**5.3 Fundamental Features (Relative)** âœ…\n",
    "- [x] P/E vs own 3-year history (z-score)\n",
    "- [x] P/S vs sector median\n",
    "- [x] Margins vs sector peers\n",
    "- [x] Revenue/earnings growth vs sector\n",
    "- [x] All ratios rank-transformed cross-sectionally\n",
    "\n",
    "**5.4 Event & Calendar Features** âœ…\n",
    "- [x] Days to next earnings\n",
    "- [x] Days since last earnings\n",
    "- [x] Post-earnings drift window indicator (PEAD 63 days)\n",
    "- [x] Surprise magnitude (last N quarters)\n",
    "- [x] Surprise streak and cross-sectional z-score\n",
    "- [x] Filing recency (days since last 10-Q/10-K)\n",
    "\n",
    "**5.5 Regime & Macro Features** âœ…\n",
    "- [x] VIX level and percentile (2-year window)\n",
    "- [x] VIX regime classification (low/normal/elevated/high)\n",
    "- [x] Market trend regime (bull/bear/neutral)\n",
    "- [x] Sector rotation indicators (tech vs defensives)\n",
    "- [x] All features timestamped with cutoff enforcement\n",
    "\n",
    "**5.6 Missingness Masks** âœ…\n",
    "- [x] Create explicit \"known at time T\" indicators\n",
    "- [x] Missingness as first-class feature (not just imputation)\n",
    "- [x] Track data coverage statistics by category\n",
    "- [x] Generate coverage reports\n",
    "\n",
    "**5.7 Feature Hygiene & Redundancy** âœ…\n",
    "- [x] Cross-sectional z-score/rank standardization\n",
    "- [x] Rolling Spearman correlation matrix\n",
    "- [x] Feature clustering (identify blocks)\n",
    "- [x] VIF diagnostics (tabular features)\n",
    "- [x] Rolling IC stability checks\n",
    "- [x] Sign consistency analysis\n",
    "\n",
    "**5.8 Feature Neutralization (Diagnostics)** âœ…\n",
    "- [x] Sector-neutral IC computation\n",
    "- [x] Beta-neutral IC computation\n",
    "- [x] Sector+Beta neutral IC computation\n",
    "- [x] Delta (Î”) reporting for interpretation\n",
    "\n",
    "**Testing & Validation** âœ…\n",
    "- [x] Unit tests for each feature block (5.1-5.7 all have tests)\n",
    "- [x] PIT violation scanner on all features\n",
    "- [x] Univariate IC â‰¥ 0.03 check for strong signals (IC tools available)\n",
    "- [x] IC stability across rolling windows (FeatureHygiene.compute_ic_stability)\n",
    "- [x] Feature coverage > 95% (MissingnessTracker.compute_coverage_stats)\n",
    "\n",
    "---\n",
    "\n",
    "### 5.1 Targets (Labels) âœ… COMPLETE\n",
    "**Implemented in `src/features/labels.py`**\n",
    "\n",
    "**v2 (DEFAULT): Total Return Labels**\n",
    "- Forward excess returns include dividends\n",
    "- Formula: `TR_i,T(H) - TR_b,T(H)` where TR = price return + dividend yield\n",
    "- Horizons: 20 / 60 / 90 trading days\n",
    "- PIT-safe with `label_matured_at` timestamps\n",
    "\n",
    "**v1 (Legacy): Price-Only Labels**\n",
    "- Available via `label_version='v1'` flag\n",
    "- For backward compatibility only\n",
    "\n",
    "---\n",
    "\n",
    "### 5.2 Price & volume features âœ… COMPLETE\n",
    "**Implemented in `src/features/price_features.py`**\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| `mom_1m/3m/6m/12m` | Returns over 21/63/126/252 trading days |\n",
    "| `vol_20d/60d` | Annualized volatility |\n",
    "| `vol_of_vol` | Volatility of rolling volatility |\n",
    "| `max_drawdown_60d` | Maximum drawdown |\n",
    "| `rel_strength_1m/3m` | Z-score vs universe |\n",
    "| `beta_252d` | Beta vs QQQ benchmark |\n",
    "| `adv_20d/60d` | Average daily dollar volume |\n",
    "\n",
    "---\n",
    "\n",
    "### 5.3 Fundamentals (relative, normalized) âœ… COMPLETE\n",
    "**Implemented in `src/features/fundamental_features.py`**\n",
    "\n",
    "Raw ratios are avoided â€” all features are RELATIVE:\n",
    "- `pe_zscore_3y`: P/E vs own 3-year history\n",
    "- `pe_vs_sector`: P/E relative to sector median\n",
    "- `ps_vs_sector`: P/S relative to sector median\n",
    "- `gross_margin_vs_sector`: Margins vs sector\n",
    "- `revenue_growth_vs_sector`: Growth vs sector peers\n",
    "- `roe_zscore`, `roa_zscore`: Quality metrics z-scored\n",
    "\n",
    "---\n",
    "\n",
    "### Time-Decay Sample Weighting (Training Policy) âœ…\n",
    "**Implemented in `src/features/time_decay.py`**\n",
    "\n",
    "**Why time decay matters for AI stocks:**\n",
    "- AI business models and the \"AI regime\" (2020+) differ from earlier eras\n",
    "- Market microstructure evolves (HFT, retail flow)\n",
    "- Many AI stocks didn't exist 15+ years ago â€” that's OK\n",
    "- Recent observations are more relevant for forward predictions\n",
    "\n",
    "**Recommended half-lives:**\n",
    "| Horizon | Half-Life | Weight at 6y | Weight at 9y |\n",
    "|---------|-----------|--------------|--------------|\n",
    "| 20d     | 2.5 years | ~18%         | ~7%          |\n",
    "| 60d     | 3.5 years | ~30%         | ~14%         |\n",
    "| 90d     | 4.5 years | ~38%         | ~21%         |\n",
    "\n",
    "---\n",
    "\n",
    "### 5.4 Events & calendars âœ… COMPLETE\n",
    "**Implemented in `src/features/event_features.py`**\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| `days_to_earnings` | Days until next expected earnings |\n",
    "| `days_since_earnings` | Days since last report |\n",
    "| `in_pead_window` | Post-earnings drift window (63 days) |\n",
    "| `last_surprise_pct` | Most recent surprise % |\n",
    "| `avg_surprise_4q` | Rolling 4Q average |\n",
    "| `surprise_streak` | Consecutive beats/misses |\n",
    "| `surprise_zscore` | Cross-sectional z-score |\n",
    "| `days_since_10k/10q` | Filing recency |\n",
    "| `reports_bmo` | Typical announcement timing |\n",
    "\n",
    "---\n",
    "\n",
    "### 5.5 Regime & macro âœ… COMPLETE\n",
    "**Implemented in `src/features/regime_features.py`**\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| `vix_level`, `vix_percentile` | VIX level and 2-year percentile |\n",
    "| `vix_regime` | low/normal/elevated/high |\n",
    "| `market_return_5d/21d/63d` | SPY returns at various windows |\n",
    "| `market_regime` | bull/bear/neutral (MA-based) |\n",
    "| `above_ma_50`, `above_ma_200` | Price vs moving averages |\n",
    "| `tech_vs_staples/utilities` | Sector rotation signals |\n",
    "\n",
    "---\n",
    "\n",
    "### 5.6 Availability & missingness masks âœ… COMPLETE\n",
    "**Implemented in `src/features/missingness.py`**\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| `coverage_pct` | Overall feature coverage (0-1) |\n",
    "| `{category}_coverage` | Per-category availability |\n",
    "| `has_{type}_data` | Boolean availability flags |\n",
    "| `is_new_stock` | < 1 year of history |\n",
    "\n",
    "**Key Philosophy:** Missingness is a SIGNAL, not just noise.\n",
    "\n",
    "---\n",
    "\n",
    "### 5.7 Feature Hygiene & Redundancy Control âœ… COMPLETE\n",
    "**Implemented in `src/features/hygiene.py`**\n",
    "\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| Cross-sectional standardization | z-score or rank-transform within date |\n",
    "| Rolling Spearman correlation | Correlation matrix computation |\n",
    "| Feature clustering | Hierarchical clustering to identify blocks |\n",
    "| VIF diagnostics | Variance Inflation Factor (diagnostic, not filter) |\n",
    "| IC stability analysis | Rolling IC with sign consistency tracking |\n",
    "\n",
    "> **Principle**: A feature with IC 0.04 once and âˆ’0.01 later is worse than IC 0.02 stable forever.\n",
    "\n",
    "---\n",
    "\n",
    "### 5.8 Feature Neutralization âœ… COMPLETE\n",
    "**Implemented in `src/features/neutralization.py`**\n",
    "\n",
    "**Purpose:** For diagnostics ONLY (not training). Reveals WHERE alpha comes from.\n",
    "\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| Sector-neutral IC | IC after removing sector effects |\n",
    "| Beta-neutral IC | IC after removing market beta |\n",
    "| Sector+Beta neutral IC | IC after removing both factors |\n",
    "| Delta (Î”) reporting | neutral_IC - raw_IC for interpretation |\n",
    "\n",
    "**Interpretation:**\n",
    "- Large negative Î”_sector â†’ feature was mostly sector rotation\n",
    "- Large negative Î”_beta â†’ feature was mostly market exposure\n",
    "- Small Î” â†’ alpha is genuinely stock-specific\n",
    "\n",
    "---\n",
    "\n",
    "**Feature success criteria** âœ…\n",
    "- > 95% completeness (post-masking)\n",
    "- Strong univariate signals show IC â‰³ 0.03\n",
    "- No feature introduces PIT violations\n",
    "- **Stability**: IC sign consistent across â‰¥70% of rolling windows\n",
    "- **Redundancy understood**: Feature blocks documented, correlation matrix computed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Evaluation Framework (Core Credibility Layer) âœ… CLOSED & FROZEN\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”’ CHAPTER 6 FREEZE STATUS\n",
    "\n",
    "**Status:** CLOSED & FROZEN (December 30, 2025)  \n",
    "**Tests:** 413/413 passing  \n",
    "**Commits:**\n",
    "- `18bad8a` - Chapter 6: Closure fixes + freeze REAL baseline reference\n",
    "- `7e6fa3a` - Chapter 6: Freeze REAL baseline reference artifacts\n",
    "\n",
    "**Frozen Baseline Floor (REAL DuckDB Data):**\n",
    "\n",
    "| Horizon | Best Baseline | Median RankIC | Quintile Spread | Hit Rate @10 | N Folds |\n",
    "|---------|---------------|---------------|-----------------|--------------|---------|\n",
    "| **20d** | `mom_12m_monthly` | **0.0283** | 0.0035 | 0.50 | 109 |\n",
    "| **60d** | `momentum_composite_monthly` | **0.0392** | 0.0370 | 0.60 | 109 |\n",
    "| **90d** | `momentum_composite_monthly` | **0.0169** | 0.0374 | 0.60 | 109 |\n",
    "\n",
    "**Sanity Check:** âœ… PASSED (`naive_random` RankIC â‰ˆ 0 for all horizons)\n",
    "\n",
    "**Frozen Artifacts (tracked in git):**\n",
    "- `evaluation_outputs/chapter6_closure_real/` - Baseline reference (IMMUTABLE)\n",
    "- `BASELINE_FLOOR.json` - Metrics to beat for Chapter 7+\n",
    "- `BASELINE_REFERENCE.md` - Usage instructions\n",
    "- `CLOSURE_MANIFEST.json` - Commit hash (`bf2cf8e`), data hash (`5723d4c88b8ecba1...`)\n",
    "\n",
    "**Data Snapshot:**\n",
    "- Source: DuckDB (`data/features.duckdb`)\n",
    "- Rows: 192,307 (2016-01-04 â†’ 2025-02-19)\n",
    "- Tickers: ~100 (AI universe)\n",
    "- Horizons: 20d, 60d, 90d (TRADING DAYS)\n",
    "- Label Version: v2 (total return with dividends)\n",
    "\n",
    "**Reference Doc:** See `CHAPTER_6_FREEZE.md` for complete details.\n",
    "\n",
    "**What This Means:**\n",
    "- âœ… Chapter 6 evaluation pipeline is COMPLETE and may not be modified\n",
    "- âœ… Baseline reference is FROZEN and is the immutable comparison anchor for Chapter 7+\n",
    "- âœ… All future models must use this frozen pipeline and beat the frozen baseline floor\n",
    "- âš ï¸ Any changes to evaluation definitions require a new version and complete re-freeze\n",
    "\n",
    "---\n",
    "\n",
    "> **CRITICAL PHILOSOPHY**: \"You've crossed the line where bad evaluation can ruin a good system.\"\n",
    ">\n",
    "> **Approach**: Be conservative. Let results look \"boring\" if they are. Resist the urge to tweak features/models early. If signals survive Chapter 6 as-is, Chapters 7-11 will feel almost easy.\n",
    "\n",
    "### 6.0 Prerequisites Check âœ…\n",
    "- **Labels**: v2 total return (dividends), mature-aware, PIT-safe âœ…\n",
    "- **Features**: 5.1-5.8 complete, stable, interpretable, auditable âœ…\n",
    "- **Missingness**: Explicit, not dropped âœ…\n",
    "- **Regime**: Visible but not leaked âœ…\n",
    "- **Alpha attribution**: Neutralization working âœ…\n",
    "- **PIT discipline**: Scanner enforced, 0 CRITICAL violations âœ…\n",
    "\n",
    "---\n",
    "\n",
    "### 6.0.2 Definition Lock âœ… IMPLEMENTED\n",
    "\n",
    "> **CRITICAL**: All time conventions are locked in `src/evaluation/definitions.py`\n",
    "\n",
    "**Canonical Definitions (FROZEN):**\n",
    "\n",
    "| Parameter | Value | Unit | Enforcement |\n",
    "|-----------|-------|------|-------------|\n",
    "| **Horizons** | 20, 60, 90 | TRADING DAYS | `validate_horizon()` |\n",
    "| **Embargo** | 90 | TRADING DAYS | `validate_embargo()` |\n",
    "| **Rebalance** | 1st of month | Calendar day | Walk-forward splitter |\n",
    "| **Pricing** | Close-to-close | - | Label generator |\n",
    "| **Maturity** | label_matured_at <= cutoff_utc | UTC datetime | fold.filter_labels() |\n",
    "\n",
    "**Anti-Leakage Enforcement (HARD CONSTRAINTS):**\n",
    "```python\n",
    "# Embargo validation (raises ValueError if < 90 TRADING DAYS)\n",
    "from src.evaluation import validate_embargo\n",
    "validate_embargo(90)  # âœ… Passes\n",
    "validate_embargo(30)  # âŒ ValueError: \"must be at least 90 TRADING DAYS\"\n",
    "\n",
    "# Maturity check (UTC datetime, not naive date)\n",
    "from src.evaluation import get_market_close_utc, is_label_mature\n",
    "cutoff_utc = get_market_close_utc(date(2023, 6, 15))  # 4 PM ET â†’ UTC\n",
    "is_label_mature(label_matured_at, cutoff_date)  # Rejects naive datetimes\n",
    "```\n",
    "\n",
    "**Purging Rules (Per-Row-Per-Horizon):**\n",
    "- Train labels: Purge if T + H (trading days) > train_end\n",
    "- Val labels: Purge if T - H (trading days) < train_end\n",
    "- NOT a global rule that \"happens to work because embargo = 90\"\n",
    "\n",
    "**End-of-Sample Eligibility:**\n",
    "- All horizons (20/60/90) must be valid for an as-of date\n",
    "- No partial horizons near end of evaluation period\n",
    "- `require_all_horizons=True` in splitter\n",
    "\n",
    "**Test Coverage:** 65/65 tests passing\n",
    "- `tests/test_definitions.py`: 40 tests\n",
    "- `tests/test_walk_forward.py`: 25 tests\n",
    "\n",
    "---\n",
    "\n",
    "### 6.0.1 Pre-Implementation Sanity Checks (COMPLETE BEFORE CODING)\n",
    "\n",
    "> **CRITICAL**: These are not blockersâ€”they are sanity locks. Complete both before writing any Chapter 6 code.\n",
    "\n",
    "#### âœ… Sanity Check 1: Manual IC vs Qlib IC Parity Test\n",
    "\n",
    "**Purpose:** Ensure adapter/indexing is correct before generating hundreds of evaluation reports.\n",
    "\n",
    "**Test Protocol:**\n",
    "```python\n",
    "# One fold, one horizon, same predictions\n",
    "fold = \"2023-Q1\"\n",
    "horizon = 20\n",
    "\n",
    "# Manual RankIC calculation\n",
    "manual_rankic = df.groupby(\"date\").apply(\n",
    "    lambda x: spearmanr(x[\"prediction\"], x[\"label\"])[0]\n",
    ").median()\n",
    "\n",
    "# Qlib RankIC calculation\n",
    "qlib_df = adapter.to_qlib_format(predictions, labels)\n",
    "qlib_rankic = qlib.evaluate(qlib_df)[\"IC\"].median()\n",
    "\n",
    "# STOP if they don't match\n",
    "assert abs(manual_rankic - qlib_rankic) < 0.001, \"IC mismatch - fix adapter!\"\n",
    "```\n",
    "\n",
    "**Acceptance:** Manual and Qlib RankIC must agree to 3 decimal places.\n",
    "\n",
    "**If they don't match â†’ STOP immediately:**\n",
    "- Check MultiIndex formatting (datetime, instrument)\n",
    "- Check date alignment (T vs T+H)\n",
    "- Check for missing data handling differences\n",
    "- Check for sign flips (prediction vs label)\n",
    "\n",
    "#### âœ… Sanity Check 2: Experiment Naming Convention\n",
    "\n",
    "**Purpose:** Prevent chaos when Recorder usage explodes across hundreds of experiments.\n",
    "\n",
    "**Convention (LOCK THIS IN NOW):**\n",
    "```\n",
    "exp = ai_forecaster/\n",
    "      horizon={20,60,90}/\n",
    "      model={kronos_v0, fintext_v0, tabular_lgb, baseline_mom12m}/\n",
    "      labels={v1_priceonly, v2_totalreturn}/\n",
    "      fold={01, 02, ..., 40}/\n",
    "```\n",
    "\n",
    "**Example paths:**\n",
    "```\n",
    "ai_forecaster/horizon=20/model=kronos_v0/labels=v2/fold=03\n",
    "ai_forecaster/horizon=60/model=baseline_mom12m/labels=v2/fold=12\n",
    "ai_forecaster/horizon=90/model=tabular_lgb/labels=v2/fold=25\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 6.1 Walk-Forward Engine\n",
    "\n",
    "**Expanding window** (not rolling):\n",
    "- Grows forward, never shrinks\n",
    "- Preserves long-term signal stability\n",
    "- Avoids artificial lookback dependency\n",
    "\n",
    "**Rebalance Cadence (LOCKED):**\n",
    "\n",
    "| Frequency | Purpose | Details |\n",
    "|-----------|---------|---------|\n",
    "| **Monthly (Primary)** | Main evaluation | First trading day of month, ~110 points (2016-2025) |\n",
    "| **Quarterly (Secondary)** | Robustness check | Supplementary slice only |\n",
    "\n",
    "**Evaluation Date Range (LOCKED):**\n",
    "```python\n",
    "EVAL_START = \"2016-01-01\"  # Earliest reliable fundamentals + universe snapshots\n",
    "EVAL_END = \"2025-06-30\"    # Conservative: guarantees 90d label maturity\n",
    "```\n",
    "\n",
    "**Why these dates?**\n",
    "- **2016-01-01**: FMP fundamentals reliable, universe coverage sufficient\n",
    "- **2025-06-30**: All 90d labels mature (PIT-safe), includes 2023-25 AI rally\n",
    "- **Result**: ~110 monthly points, multiple regimes (pre-COVID, COVID, drawdown, AI mania)\n",
    "\n",
    "**Universe snapshots:**\n",
    "- Uses `stable_id` snapshots from Chapter 4 (survivorship-safe)\n",
    "- Respects `label_matured_at` timestamps (PIT-safe)\n",
    "- No forward-looking information leakage\n",
    "\n",
    "**Time-decay sample weighting** (training only):\n",
    "- From `src/features/time_decay.py`\n",
    "- Horizon-specific half-lives: 2.5y (20d), 3.5y (60d), 4.5y (90d)\n",
    "- Per-date normalization for cross-sectional ranking\n",
    "\n",
    "---\n",
    "\n",
    "### 6.1.1 Baselines (Models to Beat)\n",
    "\n",
    "**3 baselines to beat:**\n",
    "\n",
    "| Baseline | Feature(s) | Purpose |\n",
    "|----------|-----------|---------|\n",
    "| **A: `mom_12m`** | 12-month momentum | Primary naive baseline (embarrassing if we can't beat) |\n",
    "| **B: `momentum_composite`** | `(mom_1m + mom_3m + mom_6m + mom_12m) / 4` | Stronger but transparent |\n",
    "| **C: `short_term_strength`** | `mom_1m` or `rel_strength_1m` | Diagnostic for horizon sensitivity |\n",
    "\n",
    "**+ 1 sanity baseline (not a target):**\n",
    "- **`naive_random`**: Deterministic random scores (sanity check: RankIC â‰ˆ 0, confirms no systematic bias)\n",
    "\n",
    "**Critical Guardrail:**\n",
    "All baselines run through **identical pipeline:**\n",
    "- Same universe snapshots (`stable_id`)\n",
    "- Same missingness handling\n",
    "- Same neutralization setting (raw or sector/beta-neutral)\n",
    "- Same cost diagnostic treatment (6.4)\n",
    "- Same purging/embargo\n",
    "- Same walk-forward splits\n",
    "\n",
    "**No baseline shopping:** Adding more baselines = temptation to cherry-pick weak ones.\n",
    "\n",
    "---\n",
    "\n",
    "### 6.2 Label Hygiene\n",
    "**Enforce maturity rule:**\n",
    "- `label_matured_at <= asof` strictly enforced\n",
    "- No label is used before it matures\n",
    "\n",
    "**Horizon-aware purging:**\n",
    "- Remove overlapping labels across training/validation folds\n",
    "- Prevents leakage from correlated label windows\n",
    "\n",
    "**Embargo = max horizon:**\n",
    "- Gap between train and validation = 90 trading days\n",
    "- Conservative cushion for all horizons (20/60/90)\n",
    "\n",
    "---\n",
    "\n",
    "### 6.3 Metrics (Ranking-First)\n",
    "\n",
    "**Primary Metric: RankIC**\n",
    "- Spearman correlation of predicted ranks vs actual excess returns\n",
    "- More stable than Pearson IC (robust to outliers)\n",
    "- Directly measures ranking quality\n",
    "\n",
    "**IC by Regime:**\n",
    "- VIX low/high quartiles\n",
    "- Bull/bear markets (SPY 200-day MA)\n",
    "- Sector rotation periods\n",
    "\n",
    "**Top-Bottom Quintile Spread:**\n",
    "- Return of top 20% - return of bottom 20%\n",
    "- Measures practical exploitability\n",
    "\n",
    "**Top-K Definition (LOCKED):**\n",
    "\n",
    "| Metric | Primary | Secondary | Target |\n",
    "|--------|---------|-----------|--------|\n",
    "| **Top-K size** | Top-10 | Top-20 | - |\n",
    "| **Churn** | Jaccard or % retained | - | < 30% |\n",
    "| **Hit Rate** | Excess return > 0 | - | > 55% |\n",
    "\n",
    "**Churn formula:**\n",
    "```python\n",
    "churn = 1 - len(set(top_k_t) & set(top_k_t_minus_1)) / len(set(top_k_t) | set(top_k_t_minus_1))\n",
    "```\n",
    "\n",
    "**Hit Rate definition:**\n",
    "```python\n",
    "hit = (top_k_portfolio_return - benchmark_return) > 0\n",
    "hit_rate = hits / total_rebalances\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 6.4 Cost Realism (Diagnostic)\n",
    "\n",
    "**Base costs:**\n",
    "- 20 bps round-trip (conservative for liquid largecaps)\n",
    "- Higher for small/mid caps if needed\n",
    "\n",
    "**ADV-scaled slippage:**\n",
    "- Function of position size / average daily dollar volume\n",
    "- Penalizes illiquid names\n",
    "\n",
    "**Question: \"Does alpha survive?\"**\n",
    "- This is diagnostic, NOT optimization\n",
    "- If alpha vanishes post-cost â†’ reject signal\n",
    "- If survives â†’ document slippage sensitivity\n",
    "\n",
    "---\n",
    "\n",
    "### 6.5 Stability Reports\n",
    "\n",
    "**IC decay plots:**\n",
    "- How does IC degrade over time within a fold?\n",
    "- Stable signals show flat or slow decay\n",
    "- Rapid decay â†’ overfitting or regime shift\n",
    "\n",
    "**Regime-conditional performance:**\n",
    "- IC in VIX high vs low\n",
    "- IC in bull vs bear\n",
    "- IC across sectors\n",
    "\n",
    "**Churn diagnostics:**\n",
    "- Top-10 ranking turnover month-over-month\n",
    "- High churn (>50%) â†’ unstable, costly\n",
    "- Target: <30% for exploitability\n",
    "\n",
    "---\n",
    "\n",
    "### 6.6 Qlib Integration (Shadow Evaluator)\n",
    "\n",
    "**Philosophy:** Use Microsoft's Qlib as a \"shadow evaluator\" for standardized reporting, NOT as a replacement for our core infrastructure.\n",
    "\n",
    "**What Qlib Does for Us:**\n",
    "\n",
    "| Chapter 6 Component | Qlib Feature |\n",
    "|---------------------|--------------|\n",
    "| **6.3 Metrics** | Built-in IC/RankIC analysis, monthly IC, regime IC, autocorrelation plots |\n",
    "| **6.5 Reporting** | Quintile analysis, cumulative returns, long-short distribution, drawdown |\n",
    "| **6.4 Cost Realism** | Backtest engine with configurable transaction costs (second opinion) |\n",
    "| **Experiment Tracking** | Recorder system for managing walk-forward folds and model variants |\n",
    "\n",
    "**Integration Pattern (Narrow & Safe):**\n",
    "```\n",
    "Our System (source of truth) â†’ predictions + labels â†’ Qlib â†’ evaluation reports\n",
    "```\n",
    "\n",
    "**Data Flow:**\n",
    "1. Our pipeline generates: `(date, ticker, prediction, label, optional_group)`\n",
    "2. Qlib receives this DataFrame (not raw data/features)\n",
    "3. Qlib outputs: standardized factor evaluation + backtest summaries\n",
    "\n",
    "**What Qlib Does NOT Replace:**\n",
    "- âŒ Universe construction (we keep stable_id + survivorship)\n",
    "- âŒ Feature engineering (we keep PIT discipline + 5.1-5.8)\n",
    "- âŒ Label generation (we keep v2 total return)\n",
    "- âŒ Data storage (we keep DuckDB PIT store)\n",
    "\n",
    "**Implementation:**\n",
    "```python\n",
    "# Adapter layer\n",
    "def our_predictions_to_qlib_format(predictions_df, labels_df):\n",
    "    qlib_df = pd.merge(predictions_df, labels_df, on=[\"date\", \"ticker\"])\n",
    "    qlib_df = qlib_df.set_index([\"datetime\", \"instrument\"])  # Qlib format\n",
    "    return qlib_df\n",
    "\n",
    "# Generate reports\n",
    "from qlib.contrib.evaluate import backtest_daily\n",
    "reports = backtest_daily(prediction=qlib_df, ...)\n",
    "```\n",
    "\n",
    "**References:**\n",
    "- Qlib GitHub: https://github.com/microsoft/qlib\n",
    "- Qlib Docs: https://qlib.readthedocs.io/en/latest/\n",
    "- Evaluation: https://qlib.readthedocs.io/en/latest/component/report.html\n",
    "\n",
    "---\n",
    "\n",
    "**Acceptance Criteria:**\n",
    "- âœ… Median walk-forward RankIC > baseline by â‰¥ 0.02\n",
    "- âœ… Net-of-cost improvement: % positive folds â‰¥ baseline + 10pp (relative gate; frozen floor: 5.8%-40.1%)\n",
    "- âœ… Top-10 ranking churn < 30% month-over-month\n",
    "- âœ… Performance degrades gracefully under regime shifts\n",
    "- âœ… NO PIT violations (enforced by scanner)\n",
    "\n",
    "**Guardrails:**\n",
    "- âŒ NO new features mid-evaluation\n",
    "- âŒ NO retraining models to \"fix\" bad folds\n",
    "- âŒ NO cherry-picking good time periods\n",
    "- âŒ NO optimizing to costs (diagnostic only)\n",
    "- âŒ NO hiding negative results\n",
    "\n",
    "**Success = Boring Results That Don't Break**\n",
    "- Median IC of 0.03-0.05 is GOOD\n",
    "- Stable across regimes is EXCELLENT\n",
    "- Survives costs is SUFFICIENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Baseline Models (Models to Beat) âœ… IMPLEMENTED\n",
    "\n",
    "---\n",
    "\n",
    "### 7.0 Baseline Philosophy\n",
    "\n",
    "Baselines establish the **floor** that models must clear. They serve three purposes:\n",
    "\n",
    "1. **Sanity check**: If a model can't beat momentum, something is fundamentally wrong\n",
    "2. **Value demonstration**: ML must add measurable value over transparent alternatives  \n",
    "3. **Stability anchor**: Frozen baselines prevent \"drifting targets\" during model iteration\n",
    "\n",
    "**Critical rule**: Baselines are **locked before any model is trained**. No baseline shopping.\n",
    "\n",
    "---\n",
    "\n",
    "### 7.1 Baseline Categories\n",
    "\n",
    "All baselines run through the **identical evaluation pipeline** as models:\n",
    "- Same universe snapshots (stable_id + survivorship)\n",
    "- Same walk-forward folds (purging/embargo/maturity)\n",
    "- Same EvaluationRow contract\n",
    "- Same metrics, costs, and stability reports\n",
    "\n",
    "#### 7.1.1 Factor Baselines (Models Must Beat)\n",
    "\n",
    "| Baseline | Description | Formula | Purpose |\n",
    "|----------|-------------|---------|---------|\n",
    "| `mom_12m` | 12-month momentum | `score = mom_12m` | **Primary naive baseline** â€” If models can't beat this, something is wrong |\n",
    "| `momentum_composite` | Multi-horizon momentum | `score = (mom_1m + mom_3m + mom_6m + mom_12m) / 4` | **Stronger transparent baseline** â€” Realistic bar for \"is ML worth it?\" |\n",
    "| `short_term_strength` | 1-month momentum | `score = mom_1m` | **Diagnostic baseline** â€” Exposes horizon sensitivity and mean-reversion regimes |\n",
    "\n",
    "#### 7.1.2 Sanity Baselines (Pipeline Verification Only)\n",
    "\n",
    "| Baseline | Description | Formula | Purpose |\n",
    "|----------|-------------|---------|---------|\n",
    "| `naive_random` | Deterministic random | `score = hash(as_of_date, horizon, stable_id)` | **Pipeline sanity** â€” If RankIC â‰  ~0, evaluation is hallucinating alpha |\n",
    "\n",
    "**Note**: `naive_random` should NEVER be used as a \"bar to clear\". It's purely a sanity check.\n",
    "\n",
    "#### 7.1.3 ML Baselines (Tuned, Then Frozen)\n",
    "\n",
    "| Baseline | Description | Status |\n",
    "|----------|-------------|--------|\n",
    "| `tabular_lgb` | LightGBM on feature stack | ðŸ”„ TODO (Chapter 7) |\n",
    "\n",
    "The ML baseline establishes: \"Does deep learning add value over tuned gradient boosting?\"\n",
    "\n",
    "---\n",
    "\n",
    "### 7.2 Baseline Gates (Pass/Fail Thresholds)\n",
    "\n",
    "These are the minimum thresholds for each baseline category:\n",
    "\n",
    "| Gate | Metric | Threshold | What It Means |\n",
    "|------|--------|-----------|---------------|\n",
    "| **Factor Gate** | median RankIC (best factor) | â‰¥ 0.02 | Momentum signal exists in data |\n",
    "| **ML Gate** | median RankIC (tabular_lgb) | â‰¥ 0.05 | ML extracts signal beyond factors |\n",
    "| **Model Gate** | median RankIC (model) | â‰¥ ML baseline + 0.02 | Deep learning adds value |\n",
    "\n",
    "**Gating policy**:\n",
    "- Factor gate must pass before proceeding (confirms data quality)\n",
    "- ML gate establishes the \"ML floor\" for TSFM models\n",
    "- TSFM models must beat tuned ML baseline on **median OOS RankIC**\n",
    "\n",
    "---\n",
    "\n",
    "### 7.3 Running Baselines\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "from src.evaluation import (\n",
    "    ExperimentSpec,\n",
    "    run_experiment,\n",
    "    SMOKE_MODE,\n",
    "    FULL_MODE,\n",
    "    FACTOR_BASELINES,\n",
    "    SANITY_BASELINES,\n",
    ")\n",
    "\n",
    "# Run all factor baselines (SMOKE mode for CI)\n",
    "for baseline_name in FACTOR_BASELINES:\n",
    "    spec = ExperimentSpec.baseline(baseline_name, cadence=\"monthly\")\n",
    "    results = run_experiment(\n",
    "        experiment_spec=spec,\n",
    "        features_df=features,  # Your features DataFrame\n",
    "        output_dir=Path(\"evaluation_outputs\"),\n",
    "        mode=SMOKE_MODE  # or FULL_MODE for production\n",
    "    )\n",
    "    print(f\"{baseline_name}: {results['n_folds']} folds\")\n",
    "\n",
    "# Run sanity baseline (verify ~0 RankIC)\n",
    "spec = ExperimentSpec.baseline(\"naive_random\", cadence=\"monthly\")\n",
    "sanity_results = run_experiment(spec, features, Path(\"evaluation_outputs\"), SMOKE_MODE)\n",
    "assert abs(sanity_results[\"median_rankic\"]) < 0.05, \"Pipeline sanity failed!\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 7.4 Acceptance Criteria (Models Must Clear)\n",
    "\n",
    "| Criterion | Threshold | Rationale |\n",
    "|-----------|-----------|-----------|\n",
    "| **RankIC Lift** | Model median RankIC >= best baseline + 0.02 | ML must add meaningful signal |\n",
    "| **Net-Positive Folds** | >= 70% of folds positive after base costs | Signal must survive realistic trading |\n",
    "| **Top-10 Churn** | Median < 30% | Rankings must be stable enough to trade |\n",
    "| **No Collapse** | 0 folds with negative median RankIC | Robust across regimes |\n",
    "\n",
    "These criteria are computed via:\n",
    "```python\n",
    "from src.evaluation import compute_acceptance_verdict, save_acceptance_summary\n",
    "\n",
    "verdict = compute_acceptance_verdict(\n",
    "    model_summary,\n",
    "    baseline_summaries={\n",
    "        \"mom_12m\": ..., \n",
    "        \"momentum_composite\": ..., \n",
    "        \"short_term_strength\": ...,\n",
    "        \"tabular_lgb\": ...  # Once implemented\n",
    "    },\n",
    "    cost_overlays=cost_df,\n",
    "    churn_df=churn_df\n",
    ")\n",
    "save_acceptance_summary(verdict, Path(\"outputs\"), \"model_vs_baselines\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 7.5 FULL_MODE Reference Run (Required Before Model Work)\n",
    "\n",
    "**Before training any model**, freeze a FULL_MODE baseline run:\n",
    "- **Range**: 2016-01-01 â†’ 2025-06-30 (locked)\n",
    "- **Cadence**: Monthly (primary), Quarterly (robustness)\n",
    "- **Outputs**: All baselines, all 3 horizons (20/60/90)\n",
    "\n",
    "This produces:\n",
    "```\n",
    "evaluation_outputs/\n",
    "â”œâ”€â”€ baseline_mom_12m_monthly/\n",
    "â”‚   â”œâ”€â”€ eval_rows.parquet\n",
    "â”‚   â”œâ”€â”€ per_date_metrics.csv\n",
    "â”‚   â”œâ”€â”€ fold_summaries.csv\n",
    "â”‚   â”œâ”€â”€ cost_overlays.csv\n",
    "â”‚   â”œâ”€â”€ stability_scorecard.csv\n",
    "â”‚   â””â”€â”€ REPORT_SUMMARY.md\n",
    "â”œâ”€â”€ baseline_momentum_composite_monthly/\n",
    "â”œâ”€â”€ baseline_short_term_strength_monthly/\n",
    "â”œâ”€â”€ baseline_naive_random_monthly/\n",
    "â”œâ”€â”€ baseline_tabular_lgb_monthly/  # Once implemented\n",
    "â””â”€â”€ BASELINE_REFERENCE.md  # Frozen floor for all horizons\n",
    "```\n",
    "\n",
    "**Freeze requirements**:\n",
    "- Git commit hash of the run\n",
    "- Run configuration (cadence, horizons, eval range, cost scenarios)\n",
    "- Data snapshot identity (DuckDB hash + row counts)\n",
    "- Output directory + manifest\n",
    "- Environment snapshot (Python version + pip freeze)\n",
    "\n",
    "---\n",
    "\n",
    "### 7.6 Tabular ML Baseline âœ… IMPLEMENTED + FROZEN\n",
    "\n",
    "The ML baseline uses LightGBM Regressor on the same feature stack as factor baselines.\n",
    "\n",
    "#### 7.6.1 Training Protocol (Implemented)\n",
    "\n",
    "```python\n",
    "# Per-fold training using walk-forward split\n",
    "for fold in walk_forward_folds:\n",
    "    # Uses same purging + embargo + maturity\n",
    "    train_data = fold.train_df\n",
    "    val_data = fold.val_data\n",
    "    \n",
    "    # Horizon-specific models (separate model per horizon)\n",
    "    for horizon in [20, 60, 90]:\n",
    "        model = lgb.LGBMRegressor(  # Regressor (not Ranker) for continuous returns\n",
    "            objective=\"regression_l1\",\n",
    "            metric=\"rmse\",\n",
    "            n_estimators=100,  # FROZEN after initial tuning\n",
    "            learning_rate=0.05,\n",
    "            max_depth=5,\n",
    "            num_leaves=31,\n",
    "            random_state=42,\n",
    "            # Time-decay weighting: recent data weighted higher (half-life=252d)\n",
    "        )\n",
    "        model.fit(\n",
    "            train_data[features],\n",
    "            train_data[f\"excess_return_{horizon}d\"],\n",
    "            group=train_data.groupby(\"as_of_date\").size().values,\n",
    "            sample_weight=time_decay_weights  # Exponential decay\n",
    "        )\n",
    "```\n",
    "\n",
    "#### 7.6.2 Frozen Baseline Floor (COMPLETE)\n",
    "\n",
    "**Status:** FROZEN at tag `chapter7-tabular-lgb-freeze`  \n",
    "**Artifacts:** `evaluation_outputs/chapter7_tabular_lgb_full/`  \n",
    "**Reference:** `BASELINE_REFERENCE.md` + `CLOSURE_MANIFEST.json`\n",
    "\n",
    "| Horizon | Frozen Factor Floor | tabular_lgb (ML) | Lift |\n",
    "|---------|---------------------|------------------|------|\n",
    "| 20d | 0.0283 | **0.1009** | **+0.0726** |\n",
    "| 60d | 0.0392 | **0.1275** | **+0.0883** |\n",
    "| 90d | 0.0169 | **0.1808** | **+0.1639** |\n",
    "\n",
    "**Implementation complete:**\n",
    "1. âœ… One-time param tuning completed\n",
    "2. âœ… Params frozen and recorded\n",
    "3. âœ… FULL_MODE reference run executed (109 monthly folds, 36 quarterly)\n",
    "4. âœ… Artifacts frozen with git tag\n",
    "5. âœ… **ML baseline is now immutable**\n",
    "\n",
    "---\n",
    "\n",
    "### 7.7 Output Schema (EvaluationRow Contract)\n",
    "\n",
    "Every baseline (and model) produces rows in this exact format:\n",
    "\n",
    "| Field | Type | Description |\n",
    "|-------|------|-------------|\n",
    "| `as_of_date` | date | Evaluation date |\n",
    "| `ticker` | str | Stock symbol |\n",
    "| `stable_id` | str | Survivorship-safe identifier |\n",
    "| `horizon` | int | 20, 60, or 90 trading days |\n",
    "| `fold_id` | str | Walk-forward fold |\n",
    "| `score` | float | Ranking score (HIGHER = BETTER) |\n",
    "| `excess_return` | float | v2 total return vs benchmark |\n",
    "| `adv_20d` | float | Average daily volume (cost realism) |\n",
    "\n",
    "**Rules**:\n",
    "- No duplicates per (as_of_date, stable_id, horizon)\n",
    "- Missing score/return â†’ row dropped (logged)\n",
    "- Tie-breaking: deterministic via stable_id\n",
    "\n",
    "---\n",
    "\n",
    "### 7.8 Implementation Location\n",
    "\n",
    "```\n",
    "src/evaluation/baselines.py     # Baseline definitions and scoring\n",
    "src/evaluation/run_evaluation.py # End-to-end runner (SMOKE/FULL modes)\n",
    "tests/test_baselines.py         # 39 tests (monotonicity, determinism, etc.)\n",
    "tests/test_end_to_end_smoke.py  # 22 integration tests\n",
    "```\n",
    "\n",
    "**Tests**: 61 tests specific to baselines and runner, all passing.\n",
    "\n",
    "---\n",
    "\n",
    "### 7.9 What \"Done\" Looks Like\n",
    "\n",
    "When Chapter 7 baseline work is complete:\n",
    "\n",
    "```\n",
    "evaluation_outputs/\n",
    "â”œâ”€â”€ baseline_mom_12m_monthly/\n",
    "â”œâ”€â”€ baseline_mom_12m_quarterly/\n",
    "â”œâ”€â”€ baseline_momentum_composite_monthly/\n",
    "â”œâ”€â”€ baseline_momentum_composite_quarterly/\n",
    "â”œâ”€â”€ baseline_short_term_strength_monthly/\n",
    "â”œâ”€â”€ baseline_short_term_strength_quarterly/\n",
    "â”œâ”€â”€ baseline_naive_random_monthly/  # Sanity check\n",
    "â”œâ”€â”€ baseline_tabular_lgb_monthly/   # ML baseline\n",
    "â”œâ”€â”€ baseline_tabular_lgb_quarterly/\n",
    "â””â”€â”€ BASELINE_REFERENCE.md\n",
    "```\n",
    "\n",
    "The `BASELINE_REFERENCE.md` contains:\n",
    "- Median RankIC per horizon (20/60/90), monthly and quarterly\n",
    "- Churn and cost-survival diagnostics\n",
    "- Pass/fail for each baseline gate\n",
    "- Frozen commit hash + output path\n",
    "\n",
    "**This becomes the only reference point for Chapter 8+ (Kronos, FinText, Fusion).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Kronos Module (Price Dynamics)\n",
    "\n",
    "### 8.0 Prerequisites âš ï¸ REQUIRED BEFORE STARTING\n",
    "\n",
    "**Feature Store Expansion (Pre-Chapter-8 Task)**\n",
    "\n",
    "Current DuckDB only has **7 features**. Need to expand to **50 features** before Kronos:\n",
    "\n",
    "**Priority 1: Price/Volume (14 features) - REQUIRED**\n",
    "- Add: `vol_of_vol`, `max_drawdown_60d`, `dist_from_high_60d`\n",
    "- Add: `rel_strength_1m`, `rel_strength_3m`, `beta_252d`\n",
    "- Status: Code exists in `src/features/price_features.py`, needs wiring to DuckDB\n",
    "\n",
    "**Priority 2: Events/Earnings (12 features) - CRITICAL for Earnings Gap Issue**\n",
    "- Add: `days_to_earnings`, `days_since_earnings`, `in_pead_window`, `pead_window_day`\n",
    "- Add: `last_surprise_pct`, `avg_surprise_4q`, `surprise_streak`, `surprise_zscore`, `earnings_vol`\n",
    "- Add: `days_since_10k`, `days_since_10q`, `reports_bmo`\n",
    "- Status: Code exists in `src/features/event_features.py`, needs wiring to DuckDB\n",
    "\n",
    "**Priority 3: Regime/Macro (15 features) - Optional for Ch8, Required for Ch12**\n",
    "- Add: VIX features, market regime, sector rotation\n",
    "- Status: Code exists in `src/features/regime_features.py`\n",
    "\n",
    "**Priority 4: Fundamentals (7 features) - Optional (FMP Premium available)**\n",
    "- Add: P/E, P/S, margins, ROE/ROA\n",
    "- Status: Code exists in `src/features/fundamental_features.py`\n",
    "\n",
    "**Action Required:**\n",
    "```bash\n",
    "# Expand scripts/build_features_duckdb.py to call all feature generators\n",
    "# Then rebuild:\n",
    "python scripts/build_features_duckdb.py --auto-normalize-splits\n",
    "```\n",
    "\n",
    "**Note:** Chapter 7 baseline is frozen (uses only 13 features). Expanding DuckDB does NOT invalidate frozen artifacts.\n",
    "\n",
    "---\n",
    "\n",
    "### 8.1 Kronos Model Integration\n",
    "\n",
    "- Input: OHLCV sequences\n",
    "- Rolling / ReVIN-style normalization\n",
    "- Outputs: embeddings and horizon-aware signals\n",
    "- Fine-tuning via walk-forward only\n",
    "\n",
    "**Kronos success criteria**\n",
    "- Zero-shot IC measured\n",
    "- Fine-tuning improves IC by â‰¥ 0.01\n",
    "- Stable behavior across price level shifts\n",
    "- Must beat frozen ML baseline: 0.1009/0.1275/0.1808 + 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) FinText-TSFM Module (Return Structure)\n",
    "\n",
    "- Input: historical excess returns\n",
    "- Year-specific checkpoints to reduce pretraining leakage\n",
    "- Outputs: return distributions and embeddings\n",
    "\n",
    "**FinText success criteria**\n",
    "- Adds independent signal (low correlation with Kronos)\n",
    "- Improves fusion IC consistently across regimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) NLP Sentiment (Separate)\n",
    "\n",
    "- Finance-specific NLP model (news / transcripts)\n",
    "- Strict cutoff-time enforcement\n",
    "\n",
    "Sentiment is optional and never required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Fusion Model (Ranking-First)\n",
    "\n",
    "- Gated fusion of:\n",
    "  - Kronos embeddings\n",
    "  - FinText-TSFM embeddings\n",
    "  - Tabular context features\n",
    "\n",
    "  ### Training\n",
    "- **Time-decay sample weighting** (from `src/features/time_decay.py`)\n",
    "- Per-date normalization for cross-sectional ranking loss\n",
    "\n",
    "### Objectives\n",
    "- Primary: pairwise / listwise ranking loss\n",
    "- Secondary: distribution calibration loss\n",
    "- No pure MSE price regression\n",
    "\n",
    "### Ablation gates\n",
    "- Feature blocks removed if unstable\n",
    "- Fusion must beat best single model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12) Regime-Aware Ensembling\n",
    "\n",
    "- Components: Fusion, ML baseline, simple factor\n",
    "- Regime detector (volatility / trend)\n",
    "- Smooth, regularized ensemble weights\n",
    "\n",
    "**Success criteria**\n",
    "- Ensemble improves median IC\n",
    "- Reduces variance across regimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13) Calibration & Confidence\n",
    "\n",
    "- Quantile calibration\n",
    "- Confidence stratification\n",
    "\n",
    "**Success criteria**\n",
    "- Quantile coverage error < 5%\n",
    "- High-confidence bucket materially outperforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14) Monitoring & Research Ops\n",
    "\n",
    "- Prediction logging with timestamps\n",
    "- Matured-label scoring\n",
    "- Feature and performance drift detection\n",
    "\n",
    "Alerts:\n",
    "- RankIC decay\n",
    "- Calibration breakdown\n",
    "- Ranking instability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15) Outputs & Interfaces\n",
    "\n",
    "- Ranked stock lists\n",
    "- Per-stock explanation summaries\n",
    "- Batch scoring interface\n",
    "- Full traceability of inputs and decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16) Global Research Acceptance Criteria\n",
    "\n",
    "A model is considered **valid** if:\n",
    "\n",
    "- Median walk-forward RankIC exceeds baseline by â‰¥ 0.02\n",
    "- Net-of-cost performance positive in â‰¥ 70% of folds\n",
    "- Top-10 ranking churn < 30% month-over-month\n",
    "- Performance degrades gracefully under regime shifts\n",
    "- No PIT or survivorship violations detected\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
